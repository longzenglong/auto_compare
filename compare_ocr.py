
#!/usr/bin/env python
# compare_ocr.py  â€”â€”  åœ¨ PyCharm å³é”® â–¶ Run å³å¯
from __future__ import annotations
import re, logging, warnings, shutil, difflib
from pathlib import Path
from typing import Dict, List
from tkinter import filedialog, Tk
import os
import numpy as np
import cv2, fitz                     # PyMuPDF â‰¤ 1.22.3
import pandas as pd
from paddleocr import PaddleOCR, draw_ocr
from PIL import Image
import sys
import platform
from pathlib import Path
def _default_font() -> str | None:
    """Return a reasonable CJK font path, or None."""
    if platform.system() == "Windows":
        # å¸¸è§å®‹ä½“/ä»¿å®‹/é»‘ä½“ï¼›æŒ‰å­˜åœ¨ä¼˜å…ˆè¿”å›
        for fn in ("simfang.ttf", "simsun.ttc", "msyh.ttc", "msyh.ttf"):
            p = Path(r"C:\Windows\Fonts") / fn
            if p.exists():
                return str(p)
        return None
    elif platform.system() == "Darwin":
        # macOS
        for fn in (
            "/System/Library/Fonts/STHeiti Medium.ttc",
            "/System/Library/Fonts/STHeiti Light.ttc",
            "/System/Library/Fonts/PingFang.ttc",
        ):
            if Path(fn).exists():
                return fn
        return None
    else:
        # Linux
        for fn in ("/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc",
                   "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc"):
            if Path(fn).exists():
                return fn
        return None
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å…¨å±€å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ID_RE       = re.compile(r"\d{17}[\dXx]")          # èº«ä»½è¯æ­£åˆ™
SCHOOL_KWS  = ["å¤§å­¦", "å­¦é™¢", "å­¦æ ¡"]             # å­¦æ ¡å…³é”®è¯
ID_INLINE_STOP_KWS = ["æ€§åˆ«", "æ°‘æ—", "å‡ºç”Ÿ", "å‡ºç”Ÿæ—¥æœŸ", "ä½å€",
                      "å…¬æ°‘èº«ä»½å·ç ", "å…¬æ°‘", "å·ç "]  # è¡Œå†…å­—æ®µç»ˆæ­¢å…³é”®è¯ï¼ˆæ–°å¢â€œå‡ºç”Ÿæ—¥æœŸâ€ï¼‰
FONT_PATH = _default_font()

EDU_KEYWORDS = [
    "åšå£«ç ”ç©¶ç”Ÿ", "åšå£«",
    "ç¡•å£«ç ”ç©¶ç”Ÿ", "ç ”ç©¶ç”Ÿ", "ç¡•å£«",
    "å¤§å­¦æœ¬ç§‘", "æœ¬ç§‘",
    "å¤§ä¸“", "ä¸“ç§‘",
    "ä¸­ä¸“", "é«˜ä¸­", "èŒé«˜", "æŠ€æ ¡",
]

# å­¦ä½å…³é”®è¯ï¼ˆæˆäºˆå­¦ä½ / å­¦å£«ç¡•å£«åšå£«ï¼‰
DEGREE_KEYWORDS = [
    "åšå£«å­¦ä½", "åšå£«",
    "ç¡•å£«å­¦ä½", "ç¡•å£«",
    "å­¦å£«å­¦ä½", "å­¦å£«", "åŒå­¦å£«",
]
EDU_CANON = {
    "åšå£«ç ”ç©¶ç”Ÿ": "åšå£«",
    "åšå£«": "åšå£«",
    "ç¡•å£«ç ”ç©¶ç”Ÿ": "ç ”ç©¶ç”Ÿ",
    "ç ”ç©¶ç”Ÿ": "ç ”ç©¶ç”Ÿ",
    "ç¡•å£«": "ç ”ç©¶ç”Ÿ",
    "å¤§å­¦æœ¬ç§‘": "æœ¬ç§‘",
    "æœ¬ç§‘": "æœ¬ç§‘",
    "å¤§ä¸“": "å¤§ä¸“",
    "ä¸“ç§‘": "å¤§ä¸“",
    "ä¸­ä¸“": "ä¸­ä¸“",
    "é«˜ä¸­": "é«˜ä¸­",
    "èŒé«˜": "é«˜ä¸­",
    "æŠ€æ ¡": "ä¸­ä¸“",
}

DEGREE_CANON = {
    "åšå£«å­¦ä½": "åšå£«",
    "åšå£«": "åšå£«",
    "ç¡•å£«å­¦ä½": "ç¡•å£«",
    "ç¡•å£«": "ç¡•å£«",
    "å­¦å£«å­¦ä½": "å­¦å£«",
    "å­¦å£«": "å­¦å£«",
    "åŒå­¦å£«": "å­¦å£«",  # å¦‚éœ€å•ç‹¬å¤„ç†å¯æ”¹
}
EXACT_FIELDS = ["èº«ä»½è¯å·", "æ€§åˆ«", "å‡ºç”Ÿæ—¥æœŸ", "æ°‘æ—", "å­¦ä½"]
FUZZY_FIELDS = ["ç±è´¯", "å­¦å†", "å‡ºç”Ÿåœ°"]

logging.basicConfig(level=logging.INFO,
                    format="%(levelname)s - %(message)s")
warnings.filterwarnings("ignore", category=UserWarning, module="fitz")

ocr = PaddleOCR(lang="ch", show_log=False)         # å•ä¾‹

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ OCR å·¥å…·å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pdf_to_images(pdf: Path, dpi: int = 300) -> List[np.ndarray]:
    """PyMuPDF æŠŠ PDF æ¯é¡µæ¸²æŸ“æˆ RGB ndarray"""
    doc = fitz.open(pdf)
    for p in doc:
        pix = p.get_pixmap(dpi=dpi)
        img = np.frombuffer(pix.samples, np.uint8).reshape(pix.height, pix.width, pix.n)
        yield cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
def pick_edu_keyword(texts: List[str]) -> str:
    """éå† OCR æ–‡æœ¬ï¼ŒæŒ‰ EDU_KEYWORDS é¡ºåºæ‰¾å­¦å†å…³é”®è¯å¹¶æ ‡å‡†åŒ–ã€‚"""
    full = "".join(texts)
    for kw in EDU_KEYWORDS:
        if kw in full:
            return EDU_CANON.get(kw, kw)
    # å†é€è¡Œï¼ˆå†—ä½™é˜²å®ˆï¼Œé¿å… join åè¢«æ–­å­—ï¼‰
    for t in texts:
        for kw in EDU_KEYWORDS:
            if kw in t:
                return EDU_CANON.get(kw, kw)
    return ""

def app_root() -> Path:
    """Return directory where the program is running.
    Works for PyInstaller (sys._MEIPASS) and normal script."""
    if getattr(sys, "frozen", False) and hasattr(sys, "_MEIPASS"):
        return Path(sys._MEIPASS)  # type: ignore[attr-defined]
    return Path(__file__).resolve().parent

def pick_degree_keyword(texts: List[str]) -> str:
    """éå† OCR æ–‡æœ¬ï¼ŒæŒ‰ DEGREE_KEYWORDS é¡ºåºæ‰¾å­¦ä½å…³é”®è¯å¹¶æ ‡å‡†åŒ–ã€‚"""
    full = "".join(texts)
    for kw in DEGREE_KEYWORDS:
        if kw in full:
            return DEGREE_CANON.get(kw, kw)
    for t in texts:
        for kw in DEGREE_KEYWORDS:
            if kw in t:
                return DEGREE_CANON.get(kw, kw)
    # å¸¸è§â€œå·¥å­¦å­¦å£«â€â€œæ–‡å­¦ç¡•å£«â€ç­‰ï¼šæŠ“æœ«å°¾å­¦å£«/ç¡•å£«/åšå£«
    joined = "".join(texts)
    m = re.search(r"(åšå£«|ç¡•å£«|å­¦å£«)", joined)
    if m:
        return DEGREE_CANON.get(m.group(1), m.group(1))
    return ""


def save_vis(img_src, ocr_res, save_path: Path):
    """æŠŠ OCR æ£€æµ‹æ¡† + æ–‡æœ¬ç”»åœ¨å›¾ç‰‡å¹¶ä¿å­˜"""
    img = (cv2.cvtColor(cv2.imread(str(img_src)), cv2.COLOR_BGR2RGB)
           if isinstance(img_src, (str, Path)) else img_src.copy())
    boxes  = [r[0] for r in ocr_res]
    texts  = [r[1][0] for r in ocr_res]
    scores = [r[1][1] for r in ocr_res]
    vis = draw_ocr(img, boxes, texts, scores, font_path=FONT_PATH)
    Image.fromarray(vis).save(save_path, quality=95)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ å­—æ®µæŠ½å– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def pick_school(texts: list[str]) -> str:
    """æå–å­¦æ ¡å"""
    for i, t in enumerate(texts):
        if any(k in t for k in SCHOOL_KWS):
            if "åç§°" not in t:
                return t.strip()
            if i + 1 < len(texts):
                nxt = texts[i + 1].strip()
                if any(k in nxt for k in SCHOOL_KWS):
                    return nxt
    return ""

DATE_DIGIT_TRANS = str.maketrans("ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™", "0123456789")

def pick_birth(texts: List[str]) -> str:
    """
    ä» OCR åˆ—è¡¨ä¸­æå–å‡ºç”Ÿæ—¥æœŸã€‚
    ä¼˜å…ˆè§£æåŒä¸€è¡Œï¼ˆ'å‡ºç”Ÿ2000å¹´6æœˆ2æ—¥' / 'å‡ºç”Ÿæ—¥æœŸï¼š2000-06-02'ï¼‰ï¼Œ
    æ‰¾ä¸åˆ°å† fallback åˆ°æ ‡ç­¾è¡Œä¸‹ä¸€è¡Œæ¨¡å¼ã€‚
    """
    # â‘  è¡Œå†…æˆªå–
    for t in texts:
        if "å‡ºç”Ÿ" in t:
            # å»æ‰å…¨è§’ç©ºæ ¼
            line = t.replace("\u3000", "").strip()
            # æˆª label åé¢
            if "å‡ºç”Ÿæ—¥æœŸ" in line:
                seg = line.split("å‡ºç”Ÿæ—¥æœŸ", 1)[1]
            else:
                seg = line.split("å‡ºç”Ÿ", 1)[1]
            seg = seg.replace("ï¼š", "").replace(":", "").strip()
            # åˆ‡æ‰ä¸‹ä¸€æ ‡ç­¾ï¼ˆä½å€ç­‰ï¼‰
            for stop in ID_INLINE_STOP_KWS:
                if stop in seg:
                    seg = seg.split(stop, 1)[0]
            seg = seg.strip()
            if seg:
                return seg

    # â‘¡ æ²¡æœ‰è¡Œå†…ï¼Œèµ°åŸæ¥çš„â€œä¸‹ä¸€è¡Œâ€é€»è¾‘
    val = pick_following("å‡ºç”Ÿæ—¥æœŸ", texts)
    if not val:
        val = pick_following("å‡ºç”Ÿ", texts)
    return val

def normalize_date(s: str) -> str:
    """
    å°†å„ç§æ—¥æœŸå½¢å¼æ ‡å‡†åŒ–ä¸º YYYY-MM-DDï¼›æ— æ³•è§£æåˆ™è¿”å›åŸä¸²å»ç©ºæ ¼ã€‚
    æ”¯æŒï¼š2000å¹´6æœˆ2æ—¥ / 2000-06-02 / 2000/6/2 / 20000602 / 2000å¹´06æœˆ02æ—¥ ç­‰ã€‚
    """
    if not s:
        return ""
    s = str(s).strip().translate(DATE_DIGIT_TRANS)
    # å¸¸è§åˆ†éš”ç¬¦ç»Ÿä¸€
    s_clean = re.sub(r"[./ï¼_å¹´æœˆæ—¥\s]+", "-", s)
    s_clean = s_clean.strip("-")
    # çº¯ 8 ä½æ•°å­—
    m = re.fullmatch(r"(\d{4})[-]?(\d{2})[-]?(\d{2})", s_clean)
    if m:
        y, mth, d = m.groups()
        return f"{int(y):04d}-{int(mth):02d}-{int(d):02d}"
    # éçº¯æ•°å­—ï¼šæŠ“ 3 ç»„æ•°
    m = re.search(r"(\d{4}).*?(\d{1,2}).*?(\d{1,2})", s_clean)
    if m:
        y, mth, d = m.groups()
        return f"{int(y):04d}-{int(mth):02d}-{int(d):02d}"
    return s  # fallback åŸæ ·
def pick_inline_segment(line: str, label: str, stops: List[str]) -> str:
    """
    ä»å•è¡Œä¸­æå– label åé¢çš„å†…å®¹ï¼Œé‡åˆ° stops ä¸­ä»»ä¸€æ ‡ç­¾å°±æˆªæ–­ã€‚
    ä¾‹: line='æ€§åˆ«ç”·æ°‘æ—æ±‰' â†’ pick_inline_segment(...,'æ€§åˆ«') è¿”å› 'ç”·'
    """
    if label not in line:
        return ""
    seg = line.split(label, 1)[1]  # label ä¹‹åçš„éƒ¨åˆ†
    for s in stops:
        if s != label and s in seg:
            seg = seg.split(s, 1)[0]
    return seg.replace("ï¼š", "").replace(":", "").strip()

def pick_following(label_kw: str, texts: list[str]) -> str:
    """å…ˆæ‰¾â€˜æ ‡ç­¾è¡Œ â†’ ä¸‹ä¸€è¡Œâ€™ï¼›å¦åˆ™ä»åŒä¸€è¡Œæˆªå–"""
    for i, t in enumerate(texts):
        if t.strip().startswith(label_kw):
            return texts[i + 1].strip() if i + 1 < len(texts) else ""
    for t in texts:
        if label_kw in t and len(t.strip()) > len(label_kw):
            return (t.replace(label_kw, "")
                     .replace("ï¼š", "")
                     .replace(":", "")
                     .strip())
    return ""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ èº«ä»½è¯è¡Œå†…å­—æ®µï¼ˆæ€§åˆ« / æ°‘æ— / å‡ºç”Ÿæ—¥æœŸï¼‰è§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_id_inline_fields(texts: List[str]) -> Dict[str, str]:
    """
    æ‰«æ OCR æ–‡æœ¬åˆ—è¡¨ï¼Œè§£æèº«ä»½è¯å¸¸è§åŒè¡Œæ ¼å¼ï¼š
    'æ€§åˆ«ç”·æ°‘æ—æ±‰' / 'æ€§åˆ« å¥³ æ°‘æ— æ±‰æ— å‡ºç”Ÿ 2000å¹´06æœˆ02æ—¥' / ...
    """
    sex = nat = birth = ""

    for line in texts:
        # æ€§åˆ«
        if "æ€§åˆ«" in line and not sex:
            seg = pick_inline_segment(line, "æ€§åˆ«", ID_INLINE_STOP_KWS)
            if seg:
                # å¸¸è§„ï¼šå–ç¬¬ä¸€ä¸ªç”·å¥³å­—
                m = re.search(r"[ç”·å¥³]", seg)
                sex = m.group(0) if m else seg[:1]

        # æ°‘æ—
        if "æ°‘æ—" in line and not nat:
            seg = pick_inline_segment(line, "æ°‘æ—", ID_INLINE_STOP_KWS)
            if seg:
                # å»æ‰å¯èƒ½é‡å¤çš„â€œæ—â€
                nat = seg.replace("æ—æ—", "æ—").strip()

        # å‡ºç”Ÿ / å‡ºç”Ÿæ—¥æœŸ
        if ("å‡ºç”Ÿæ—¥æœŸ" in line or "å‡ºç”Ÿ" in line) and not birth:
            # ä¼˜å…ˆé•¿æ ‡ç­¾
            seg = pick_inline_segment(line, "å‡ºç”Ÿæ—¥æœŸ", ID_INLINE_STOP_KWS)
            if not seg:
                seg = pick_inline_segment(line, "å‡ºç”Ÿ", ID_INLINE_STOP_KWS)
            if seg:
                # æ­£åˆ™è§„èŒƒåŒ–æ—¥æœŸ
                m = re.search(r"\d{4}[å¹´./-]?\s*\d{1,2}[æœˆ./-]?\s*\d{1,2}æ—¥?", seg)
                birth = m.group(0) if m else seg.strip()

    # è‹¥åŒè¡Œæœªå–åˆ°ï¼Œç”¨æ­£åˆ™å…¨å±€å…œåº•
    joined = "\n".join(texts)
    if not sex:
        m = re.search(r"æ€§åˆ«[:ï¼š]?\s*([ç”·å¥³])", joined)
        if m: sex = m.group(1)
    if not nat:
        m = re.search(r"æ°‘æ—[:ï¼š]?\s*(\S{1,5})", joined)
        if m: nat = m.group(1)
    if not birth:
        m = re.search(r"å‡ºç”Ÿ(?:æ—¥æœŸ)?[:ï¼š]?\s*(\d{4}[å¹´./-]?\s*\d{1,2}[æœˆ./-]?\s*\d{1,2}æ—¥?)", joined)
        if m: birth = m.group(1)

    return {"æ€§åˆ«": sex, "æ°‘æ—": nat, "å‡ºç”Ÿæ—¥æœŸ": birth}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ ¸å¿ƒæŠ½å–å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract(file: Path, vis_dir: Path | None = None) -> Dict[str, str]:
    """OCR æŠ½å–å…¨éƒ¨å­—æ®µ"""
    if not file or not file.exists():
        return {f: "" for f in ["èº«ä»½è¯å·", "å­¦æ ¡", "ä¸“ä¸š",
                                "æ€§åˆ«", "å‡ºç”Ÿæ—¥æœŸ", "æ°‘æ—", "ç±è´¯", "å‡ºç”Ÿåœ°", "å­¦å†", "å­¦ä½"]}

    is_pdf = file.suffix.lower() == ".pdf"
    pages  = pdf_to_images(file) if is_pdf else [str(file)]
    texts: List[str] = []

    for idx, pg in enumerate(pages, 1):
        res = ocr.ocr(pg, cls=True)[0]
        texts.extend(r[1][0] for r in res)

        if vis_dir is not None:
            vis_dir.mkdir(parents=True, exist_ok=True)
            save_vis(pg, res,
                     vis_dir / f"{file.stem}_{'page'+str(idx) if is_pdf else 'vis'}.jpg")

    full_text = "\n".join(texts)

    # â€”â€” æ–°å¢ï¼šèº«ä»½è¯åŒè¡Œå­—æ®µæŠ½å– â€”â€” #
    inline = extract_id_inline_fields(texts)

    # åŸ find_gender() æ”¹ä¸ºå†…éƒ¨å‡½æ•°ï¼Œä¿ç•™ä½ çš„é€»è¾‘ + æ­£åˆ™å…œåº•
    def find_gender() -> str:
        # ä¼˜å…ˆ inline
        if inline.get("æ€§åˆ«"):
            return inline["æ€§åˆ«"]
        # ç²¾å‡†æ­£åˆ™
        m = re.search(r"æ€§åˆ«[:ï¼š]?\s*([ç”·å¥³])", full_text)
        if m:
            return m.group(1)
        # å…¨å±€å…œåº•ï¼ˆé¿å…æ–‡ä»¶ä¸­å‡ºç°ä¸¤ä¸ªå­—è¯¯åˆ¤ï¼šè°å…ˆå‡ºç°å–è°ï¼‰
        pos_m = full_text.find("ç”·")
        pos_f = full_text.find("å¥³")
        if pos_m != -1 and (pos_f == -1 or pos_m < pos_f):
            return "ç”·"
        if pos_f != -1:
            return "å¥³"
        return ""

    # å‡ºç”Ÿæ—¥æœŸï¼ˆä¼˜å…ˆæ ‡ç­¾è¡Œï¼Œæ¬¡è¦ inlineï¼‰
    birth_raw = pick_birth(texts)
    birth_val = birth_raw or inline.get("å‡ºç”Ÿæ—¥æœŸ", "")
    # æ°‘æ—ï¼ˆä¼˜å…ˆæ ‡ç­¾è¡Œï¼Œæ¬¡è¦ inlineï¼‰
    nat_val = inline.get("æ°‘æ—", "")
    if not nat_val:
        for _line in texts:
            if "æ°‘æ—" in _line:
                nat_val = pick_inline_segment(_line, "æ°‘æ—", ID_INLINE_STOP_KWS)
                if nat_val:
                    break
    if not nat_val:
        nat_val = pick_following("æ°‘æ—", texts)
    if not nat_val:
        for _line in texts:
            if "æ€§åˆ«" in _line and "æ°‘æ—" not in _line:
                tail = _line.split("æ€§åˆ«", 1)[1]
                tail = tail.replace("ï¼š", "").replace(":", "").strip()
                tail = tail.lstrip("ç”·å¥³ ")
                cand = tail[:3].strip()
                cand = cand.replace("æ€§", "").replace("åˆ«", "").replace("ç”·", "").replace("å¥³", "").strip()
                nat_val = cand
                break
    return {
        "èº«ä»½è¯å·": (m := ID_RE.search(full_text)) and m.group(0) or "",
        "å­¦æ ¡":     pick_school(texts),
        "ä¸“ä¸š":     pick_following("ä¸“ä¸š", texts),

        # æ–°å¢å­—æ®µï¼ˆå¢å¼ºæå–ï¼‰
        "æ€§åˆ«":       find_gender(),
        "å‡ºç”Ÿæ—¥æœŸ":   birth_val,
        "æ°‘æ—":       nat_val,

        # ä¸‹åˆ—ä¿æŒåŸé€»è¾‘ï¼ˆä¸æ”¹ï¼‰
        "ç±è´¯":     pick_following("ç±è´¯", texts),
        "å‡ºç”Ÿåœ°":   pick_following("å‡ºç”Ÿåœ°", texts),
        "å­¦å†":     pick_edu_keyword(texts) or pick_following("å­¦å†", texts),
        "å­¦ä½":     pick_degree_keyword(texts) or pick_following("å­¦ä½", texts),
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ æ¯”å¯¹å‡½æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def eq(exp, act, fuzzy=False, th=90) -> bool:
    exp, act = str(exp or "").strip(), str(act or "").strip()
    if not exp or not act:
        return False
    if fuzzy:
        return difflib.SequenceMatcher(None, exp, act).ratio() * 100 >= th
    return exp == act

def ask_user_inputs() -> tuple[Path, Path]:
    """å¼¹çª—é€‰ Excel å’Œèµ„æ–™æ–‡ä»¶å¤¹"""
    root = Tk(); root.withdraw()
    excel = filedialog.askopenfilename(title="é€‰æ‹© data.xlsx",
                                       filetypes=[("Excel æ–‡ä»¶", "*.xlsx")])
    if not excel: exit("âŒæœªé€‰æ‹© Excel")
    docs = filedialog.askdirectory(title="é€‰æ‹©èµ„æ–™æ–‡ä»¶å¤¹ï¼ˆdocsï¼‰")
    if not docs: exit("âŒæœªé€‰æ‹©èµ„æ–™æ–‡ä»¶å¤¹")
    return Path(excel), Path(docs)

BIRTH_PAT = re.compile(r"(19|20\d{2}|\d{4})\D+(\d{1,2})\D+(\d{1,2})")
def eq_date(exp, act) -> bool:
    return normalize_excel_date(exp) == normalize_excel_date(act)
def find_birth(full_text: str) -> str:
    m = BIRTH_PAT.search(full_text)
    if not m:
        return ""
    y = int(m.group(1)[-4:])  # å®¹é”™ï¼šä»¥æœ€å4ä½å½“å¹´
    mm = int(m.group(2))
    dd = int(m.group(3))
    return f"{y:04d}-{mm:02d}-{dd:02d}"

def _find_doc(pdir: Path, stem: str) -> Path | None:
    """Return first match for id/bachelor/master/lvli ignoring case & multi-ext."""
    if not pdir.exists():
        return None
    patterns = [f"{stem}.*", f"{stem.upper()}.*", f"{stem.capitalize()}.*"]
    exts = ("*.pdf", "*.png", "*.jpg", "*.jpeg", "*.tif", "*.bmp")
    # å…ˆåŒ¹é… stemï¼Œä¸è¡Œå† stem+æ‰€æœ‰æ‰©å±•
    for pat in patterns:
        hits = list(pdir.glob(pat))
        if hits:
            return hits[0]
    # fallback: éå†æ‰€æœ‰æ–‡ä»¶ï¼Œçœ‹æ–‡ä»¶ååŒ…å« stemï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    for ext in exts:
        for f in pdir.glob(ext):
            if stem.lower() in f.stem.lower():
                return f
    return None

def normalize_excel_date(v: object) -> str:
    """æŠŠ Excel å•å…ƒæ ¼å€¼è½¬æˆ YYYY-MM-DD å­—ç¬¦ä¸²ã€‚
    æ”¯æŒï¼šExcel åºåˆ—å·ã€datetimeã€å„ç§å¯è§£æçš„æ—¥æœŸå­—ç¬¦ä¸²ã€åŒ…å«ä¸­æ–‡å¹´æœˆæ—¥çš„å­—ç¬¦ä¸²ã€‚
    éæ³•/ç©º -> ''"""
    if v is None or (isinstance(v, float) and pd.isna(v)):
        return ""
    s = str(v).strip()
    if not s:
        return ""

    # çº¯æ•°å­—ï¼šå¯èƒ½æ˜¯ Excel åºåˆ—å·
    if s.isdigit():
        try:
            dt = pd.to_datetime(float(s), unit="d", origin="1899-12-30", errors="raise")
            return dt.strftime("%Y-%m-%d")
        except Exception:
            pass

    # æ™®é€šæ—¥æœŸè§£æ
    dt = pd.to_datetime(s, errors="coerce")
    if pd.notna(dt):
        return dt.strftime("%Y-%m-%d")

    # ä¸­æ–‡æ ¼å¼: 2000å¹´6æœˆ2æ—¥ / 2000å¹´06æœˆ02æ—¥ ç­‰
    m = re.search(r"(\d{4})\D+(\d{1,2})\D+(\d{1,2})", s)
    if m:
        y, mth, d = map(int, m.groups())
        return f"{y:04d}-{mth:02d}-{d:02d}"

    return s  # å®åœ¨ä¸è¡ŒåŸæ ·è¿”å›

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ä¸»æµç¨‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    proj_root = app_root()
    excel, docs = ask_user_inputs()          # å¼¹çª—äº¤äº’
    try:
        shutil.copy(excel, proj_root / "data.xlsx")
    except Exception:
        pass

    vis_root = proj_root / "vis_results"
    df   = pd.read_excel(excel, dtype=str).fillna("")
    # å‡ºç”Ÿæ—¥æœŸåˆ—å½’ä¸€åŒ–
    if "å‡ºç”Ÿæ—¥æœŸ" in df.columns:
        df["å‡ºç”Ÿæ—¥æœŸ"] = df["å‡ºç”Ÿæ—¥æœŸ"].apply(normalize_excel_date)

    rows = []

    for _, r in df.iterrows():
        name = r["å§“å"].strip()
        pdir = docs / name
        logging.info(f"[{name}] å¤„ç†ä¸­ â€¦")

        idf = _find_doc(pdir, "id")
        baf = _find_doc(pdir, "bachelor")
        msf = _find_doc(pdir, "master")
        lvf = _find_doc(pdir, "lvli")     # ğŸ†• å±¥å†è¡¨ (å¯é€‰)

        id_info = extract(idf, vis_root / name)
        ba_info = extract(baf, vis_root / name)
        ms_info = extract(msf, vis_root / name)
        lv_info = extract(lvf, vis_root / name)     # æ–°è¡¨å­—æ®µ


        row = {
            "å§“å": name,

            # â€”â€” èº«ä»½è¯ä¿¡æ¯ â€”â€”ï¼ˆæ¥æºä¼˜å…ˆ id_infoï¼Œæ²¡æœ‰åˆ™ç”¨ lv_infoï¼‰
            "èº«ä»½è¯åŒ¹é…": eq(r["èº«ä»½è¯å·"], id_info["èº«ä»½è¯å·"] or lv_info["èº«ä»½è¯å·"]),
            "æ€§åˆ«åŒ¹é…":   eq(r["æ€§åˆ«"],   lv_info["æ€§åˆ«"]),
            "å‡ºç”Ÿæ—¥æœŸåŒ¹é…": eq_date(r["å‡ºç”Ÿæ—¥æœŸ"], id_info["å‡ºç”Ÿæ—¥æœŸ"] or lv_info["å‡ºç”Ÿæ—¥æœŸ"]),

            "æ°‘æ—åŒ¹é…":   eq(r["æ°‘æ—"],   id_info["æ°‘æ—"]),
            "å­¦ä½åŒ¹é…":   eq(r["å­¦ä½"],   lv_info["å­¦ä½"]),

            # â€”â€” æ¨¡ç³Šå­—æ®µ â€”â€”
            "ç±è´¯åŒ¹é…":   eq(r["ç±è´¯"],   lv_info["ç±è´¯"],   fuzzy=True),
            "å­¦å†åŒ¹é…":   eq(r["å­¦å†"],   lv_info["å­¦å†"],   fuzzy=True),
            "å‡ºç”Ÿåœ°åŒ¹é…": eq(r["å‡ºç”Ÿåœ°"], lv_info["å‡ºç”Ÿåœ°"], fuzzy=True),

            # â€”â€” å­¦å†æŠ¥å‘Šæ¯”å¯¹ â€”â€”
            "æœ¬ç§‘å­¦æ ¡åŒ¹é…": eq(r["æœ¬ç§‘å­¦æ ¡"], ba_info["å­¦æ ¡"], fuzzy=True),
            "æœ¬ç§‘ä¸“ä¸šåŒ¹é…": eq(r["æœ¬ç§‘ä¸“ä¸š"], ba_info["ä¸“ä¸š"], fuzzy=True),
            "ç¡•å£«å­¦æ ¡åŒ¹é…": eq(r["ç¡•å£«å­¦æ ¡"], ms_info["å­¦æ ¡"], fuzzy=True),
            "ç¡•å£«ä¸“ä¸šåŒ¹é…": eq(r["ç¡•å£«ä¸“ä¸š"], ms_info["ä¸“ä¸š"], fuzzy=True),

            # â€”â€” OCR å­—æ®µå›å¡« â€”â€”
            **{f"OCR_{k}": v for k, v in {
                **id_info, **ba_info, **ms_info, **lv_info}.items()}
        }
        rows.append(row)

    # æ§åˆ¶å°ç»“æœï¼ˆä¿æŒä½ åŸå§‹æ ¼å¼ï¼‰
    print(f"åŒ¹é…ç»“æœï¼š")
    for key in [
        "èº«ä»½è¯", "æ€§åˆ«", "å‡ºç”Ÿæ—¥æœŸ", "æ°‘æ—", "å­¦ä½",
        "ç±è´¯", "å­¦å†", "å‡ºç”Ÿåœ°",
        "æœ¬ç§‘å­¦æ ¡", "æœ¬ç§‘ä¸“ä¸š",
        "ç¡•å£«å­¦æ ¡", "ç¡•å£«ä¸“ä¸š"
    ]:
        print(f"  {key:<8}åŒ¹é…: {row.get(f'{key}åŒ¹é…', '')}")

    print(f"  æœ¬ç§‘æ•´ä½“åŒ¹é…: {row['æœ¬ç§‘å­¦æ ¡åŒ¹é…'] and row['æœ¬ç§‘ä¸“ä¸šåŒ¹é…']}")
    print(f"  ç¡•å£«æ•´ä½“åŒ¹é…: {row['ç¡•å£«å­¦æ ¡åŒ¹é…'] and row['ç¡•å£«ä¸“ä¸šåŒ¹é…']}")
    print("-" * 60)

    # å¯¼å‡º
    out = proj_root / "compare_result.xlsx"
    pd.DataFrame(rows).to_excel(out, index=False)
    logging.info(f"âœ… å®Œæˆï¼Œæ¯”å¯¹ç»“æœ â†’ {out.name}")
    logging.info(f"âœ… OCR å¯è§†åŒ– â†’ {vis_root.relative_to(proj_root)}")

if __name__ == "__main__":
    main()
